{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a82910-5efd-482b-ab83-0e7695e8792f",
   "metadata": {
    "id": "96a82910-5efd-482b-ab83-0e7695e8792f"
   },
   "source": [
    "# Sequence-to-sequence (seq2seq) Part II\n",
    "\n",
    "In Part I, we have explored Encoder-Decoder model, Transformer (from scratch) to tackle translation task. In notebook, we will explore one of the most useful transformer variants on a different task, text summarization task. We will learn T5 model which is a transformer based model and we will also learn how to fine-tune pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_rDryTF9uPbY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rDryTF9uPbY",
    "outputId": "df778cbf-8c6c-4b83-c167-3e70db3699b6"
   },
   "outputs": [],
   "source": [
    "# pip install rich\n",
    "# pip install transformers\n",
    "# pip install datasets\n",
    "# pip3 install SentencePiece\n",
    "# pip3 install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b51ae2-6120-4605-be39-ea323126677a",
   "metadata": {
    "id": "a2b51ae2-6120-4605-be39-ea323126677a"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# rich: for a better display on terminal\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, T5Tokenizer, T5ForConditionalGeneration, BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "import nltk\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "\n",
    "#uncomment this if you are not using puffer\n",
    "import os\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefad89-34c7-4d71-964a-8e2500d00946",
   "metadata": {
    "id": "baefad89-34c7-4d71-964a-8e2500d00946"
   },
   "source": [
    "## What is a Summary?\n",
    "A summary is a condensed version of an original text, usually a full article or book. Summaries are usually around a paragraph long, and may even be a few paragraphs long depending on the length of the work being condensed.\n",
    "\n",
    "Summaries are used in variety of situations. For example, you might want to summarize only the main points of a meeting with a co-worker because you're running late for another meeting. Or, let's say you want to introduce a complex design idea. You could begin by summarizing what your design would accomplish, to give key people an overall sense of your plan without overwhelming them. Students might summarize an article for a class, or when preparing and writing research papers, annotated bibliographies and essays. Abstracts and legal brief are also types of summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a117e3-e742-4a2a-9ad1-ebaa1f28b847",
   "metadata": {
    "id": "20a117e3-e742-4a2a-9ad1-ebaa1f28b847"
   },
   "source": [
    "The \"summary\" itself has some varieties and approaches.\n",
    "\n",
    "#### Types of summary\n",
    "\n",
    "* **Indicative summary** <br>\n",
    "It looks like a summary of the book. This summary describes what kinds of the story, but not tell all of the stories especially its ends (so indicative summary has only partial information).\n",
    "* **Informative summary** <br>\n",
    "In contrast to the indicative summary, the informative summary includes full information of the document.\n",
    "* **Keyword summary** <br>\n",
    "Not the text, but the words or phrases from the input document.\n",
    "* **Headline summary** <br>\n",
    "Only one line summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a865b28-5727-4f65-b378-cdd5515e5f24",
   "metadata": {
    "id": "5a865b28-5727-4f65-b378-cdd5515e5f24"
   },
   "source": [
    "## Basic Approach\n",
    "\n",
    "There are mainly two ways to make the summary. Extractive and Abstractive. In short, in extractive summarization sentences are chosen from the article(s) given as input, whereas in abstractive summarization sentences may be generated or a new representation of the article(s) may be output.\n",
    "\n",
    "### Extractive\n",
    "\n",
    "* Select relevant **phrases of the input document** and **concatenate** them to form a summary (like \"copy-and-paste\"). The network calculates the most important sentences from the article and gets them together to provide the most meaningful information from the article.\n",
    "  * Pros: They are quite robust since they use existing natural-language phrases that are taken straight from the input.\n",
    "  * Cons: But they lack in flexibility since they cannot use novel words or connectors. They also cannot paraphrase like people sometimes do (less fluent).\n",
    "\n",
    "\n",
    "### Abstractive\n",
    "\n",
    "* Generate a summary that keeps original intent. It's just like humans do. The network creates new sentences to encapsulate maximum gist of the article and generates that as output. The sentences in the summary may or may not be contained in the article.\n",
    "  * Pros: They can use words that were not in the original input. It enables to make more fluent and natural summaries.\n",
    "  * Cons: But it is also a much harder problem as you now require the model to generate coherent phrases and connectors.\n",
    "\n",
    "Extractive & Abstractive is not conflicting ways. You can use both to generate the summary. And there are a way collaborate with human.\n",
    "\n",
    "* Aided Summarization\n",
    "  * Combines automatic methods with human input.\n",
    "  * Computer suggests important information from the document, and the human decide to use it or not. It uses information retrieval, and text mining way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d4d26-4604-4340-adad-74d394cdc7c6",
   "metadata": {
    "id": "389d4d26-4604-4340-adad-74d394cdc7c6"
   },
   "source": [
    "The beginning of the abstractive summarization, [Banko et al. (2000)](http://www.anthology.aclweb.org/P/P00/P00-1041.pdf) suggest to use machine translatation model to abstractive summarization model. As like the machine translation model converts a source language text to a target one, the summarization system converts a source document to a target summary.\n",
    "\n",
    "Nowadays, **encoder-decoder** model that is one of the neural network models is mainly used in machine translation. So this model is also widely used in abstractive summarization model. [The summarization model that used encoder-decoder model first](http://www.aclweb.org/anthology/N16-1012) achieved state-of-the-art on the two sentence-level summarization dataset, DUC-2004 and Gigaword.\n",
    "\n",
    "#### Encoder-Decoder Model\n",
    "\n",
    "The encoder-decoder model is composed of encoder and decoder like its name. The encoder converts an input document to a latent representation (vector), and the decoder generates a summary by using it.\n",
    "\n",
    "One of the well-known Encoder-Decoder models is T5 which we will be using in this lecture. T5 is one of the most recent and novel transformers model. T5 in many ways is one of its kind transformers architecture that not only gives state of the art results in many NLP tasks, but also has a very radical approach to NLP tasks.\n",
    "Text-2-Text - According to the graphic taken from the T5 paper. All NLP tasks are converted to a text-to-text problem. Tasks such as translation, classification, summarization and question answering, all of them are treated as a text-to-text conversion problem, rather than seen as separate unique problem statements.\n",
    "Unified approach for NLP Deep Learning - Since the task is reflected purely in the text input and output, you can use the same model, objective, training procedure, and decoding process to ANY task. Above framework can be used for any task - show Q&A, summarization, etc.\n",
    "\n",
    "![](images/t5.png)\n",
    "\n",
    "We will be taking inputs from the T5 paper to prepare our dataset prior to fine tuning and training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099ef1a-644a-45bd-97c8-1d75af44b8fc",
   "metadata": {
    "id": "6099ef1a-644a-45bd-97c8-1d75af44b8fc"
   },
   "source": [
    "### Preparing the Dataset for data processing: Class\n",
    "We will start with creation of Dataset class - This defines how the text is pre-processed before sending it to the neural network. This dataset will be used the the Dataloader method that will feed the data in batches to the neural network for suitable training and processing. The Dataloader and Dataset will be used inside the Trainer(). \n",
    "\n",
    "#### CustomDataset Dataset Class\n",
    "\n",
    "* This class is defined to accept the data as input and generate tokenized output that is used by the T5 model for training.\n",
    "\n",
    "* add_prefix() inside Dataset Class is to add a prefix \"summarize: \", this is important when you use T5\n",
    "\n",
    "* We are using the T5 tokenizer to tokenize the data in the text and ctext column of the dataframe.\n",
    "\n",
    "* The tokenizer uses the batch_encode_plus method to perform tokenization and generate the necessary outputs, namely: source_id, source_mask from the actual text and target_id and target_mask from the summary text.\n",
    "To read further into the tokenizer, refer to this document\n",
    "\n",
    "* The CustomDataset class is used to create 1 dataset for each call, hench is called twice in the Trainer() for training and for validation.\n",
    "\n",
    "* Training Dataset is used to fine tune the model: 80% of the original data\n",
    "\n",
    "* Validation Dataset is used to evaluate the performance of the model. The model has not seen this data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e12853-3104-43d9-bafb-a9fcf170e271",
   "metadata": {
    "id": "09e12853-3104-43d9-bafb-a9fcf170e271"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creating a custom dataset for reading the dataset and\n",
    "    loading it into the dataloader to pass it to the\n",
    "    neural network for finetuning the model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, data, tokenizer, model_name, source_len, target_len, source_text, target_text, #train = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a Dataset class\n",
    "\n",
    "        Args:yo\n",
    "            data: Input data\n",
    "            tokenizer (transformers.tokenizer): Transformers tokenizer\n",
    "            source_len (int): Max length of source text\n",
    "            target_len (int): Max length of target text\n",
    "            source_text (str): column name of source text\n",
    "            target_text (str): column name of target text\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = target_len\n",
    "        \n",
    "        # Xsum contains about 200000+ samples, so lets just take a small portion\n",
    "        self.source_text = self.data[source_text][:1000]\n",
    "        if \"t5\" in model_name:\n",
    "            self.source_text = self.add_prefix(self.source_text)\n",
    "        self.target_text = self.data[target_text][1:1000]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the length of data\"\"\"\n",
    "\n",
    "        return len(self.target_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"return the input ids, attention masks and target ids\"\"\"\n",
    "\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "\n",
    "        # cleaning data so as to ensure data is in string type\n",
    "        source_text = \" \".join(source_text.split())\n",
    "        target_text = \" \".join(target_text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [source_text],\n",
    "            max_length=self.source_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [target_text],\n",
    "            max_length=self.summ_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        source_mask = source[\"attention_mask\"].squeeze()\n",
    "        target_ids = target[\"input_ids\"].squeeze()\n",
    "        target_mask = target[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
    "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
    "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
    "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    def add_prefix(self, examples):\n",
    "        prefix = \"summarize: \"\n",
    "        inputs = [prefix + doc for doc in examples]\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3de05c-6739-4ffd-bc05-2c4450be2c1d",
   "metadata": {
    "id": "3e3de05c-6739-4ffd-bc05-2c4450be2c1d"
   },
   "source": [
    "#### Fine Tuning the Model: Function\n",
    "Here we define a training function that trains the model on the training dataset created above, specified number of times (EPOCH), An epoch defines how many times the complete data will be passed through the network.\n",
    "\n",
    "This function is called in the Trainer()\n",
    "\n",
    "Following events happen in this function to fine tune the neural network:\n",
    "\n",
    "The epoch, tokenizer, model, device details, testing_ dataloader optimizer and scheduler are passed to the train () when its called from the Trainer()\n",
    "The dataloader passes data to the model based on the batch size.\n",
    "language_model_labels are calculated from the target_ids also, source_id and attention_mask are extracted.\n",
    "The model outputs first element gives the loss for the forward pass.\n",
    "Loss value is used to optimize the weights of the neurons in the network.\n",
    "After every 10 step the loss value is logged in the wandb service. This log is then used to generate graphs for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ca4fee-35b8-41c4-b135-0335ccc65d55",
   "metadata": {
    "id": "f5ca4fee-35b8-41c4-b135-0335ccc65d55"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer, scheduler):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to be called for training with the parameters passed from main function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            decoder_input_ids=y_ids,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "        if _ % 10 == 0:\n",
    "            print(\"STEP: \", _,\"/\",len(loader))\n",
    "            training_logger.add_row(str(epoch), str(f'{_}/{len(loader)}'), str(loss))\n",
    "            console.print(training_logger)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.detach()\n",
    "\n",
    "    scheduler.step()\n",
    "    losses = losses/len(loader)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee49059c-3317-46f3-8212-a2d946899422",
   "metadata": {
    "id": "ee49059c-3317-46f3-8212-a2d946899422"
   },
   "source": [
    "#### Validating the Model Performance: Function\n",
    "During the validation stage we pass the unseen data(Testing Dataset), trained model, tokenizer and device details to the function to perform the validation run. This step generates new summary for dataset that it has not seen during the training session.\n",
    "\n",
    "This function is called in the Trainer()\n",
    "\n",
    "This unseen data is the 20% of the data which was seperated during the Dataset creation stage. During the validation stage the weights of the model are not updated. We use the generate method for generating new text for the summary.\n",
    "\n",
    "It depends on the Beam-Search coding method developed for sequence generation for models with LM head.\n",
    "\n",
    "The generated text and originally summary are decoded from tokens to text and returned to the main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d7aa72-b247-419d-9a45-670761f0796b",
   "metadata": {
    "id": "c1d7aa72-b247-419d-9a45-670761f0796b"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to evaluate model for predictions\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                  input_ids = ids,\n",
    "                  attention_mask = mask, \n",
    "                  max_length=150, \n",
    "                  num_beams=2,\n",
    "                  repetition_penalty=2.5, \n",
    "                  length_penalty=1.0, \n",
    "                  early_stopping=True\n",
    "                  )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _ % 10==0:\n",
    "                console.print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379bea1-8143-4607-b11b-2bd545355443",
   "metadata": {
    "id": "b379bea1-8143-4607-b11b-2bd545355443"
   },
   "source": [
    "#### Trainer: Function\n",
    "In Trainer Function dataset, source text, target text, model parameters, output directory and device are passed into.\n",
    "\n",
    "Inside this function the tokenizer and the pretrained weights of the defined model are downloaded. Moreover our customdataset class is also called here, loader parameters are defined, loaders are created, optimizer is defined and most importanlty, training loop is called. \n",
    "\n",
    "After each time the train() is called, validate() is called after. One thing that is still missing is the performance metric.\n",
    "\n",
    "In the Seq2Seq Part I, we have learnt to implement `BLEU score`, and other evaluation methods were asked to be explored. One of the commonly used metric to evaluate a summarization task is called `ROUGE score`.\n",
    "\n",
    "#### ROUGE Score\n",
    "\n",
    "ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is essentially a set of metrics for evaluating automatic summarization of texts as well as machine translations.\n",
    "\n",
    "It works by comparing an automatically produced summary or translation against a set of reference summaries (typically human-produced). Let’s say that we have the following system and reference summaries:\n",
    "\n",
    "\n",
    "System Summary (what the machine produced): <br>\n",
    "`the cat was found under the bed`\n",
    "\n",
    "Reference Summary (gold standard — usually by humans):<br>\n",
    "`the cat was under the bed`\n",
    "\n",
    "If we consider just the individual words, the number of overlapping words between the system summary and reference summary is 6. This, however, does not tell you much as a metric. To get a good quantitative value, we can actually compute the precision and recall using the overlap.\n",
    "\n",
    "Simply put, recall (in the context of ROUGE) refers to how much of the reference summary the system summary is recovering or capturing. If we are just considering the individual words, it can be computed as:\n",
    "\n",
    "$$  \\big( \\frac{number\\:of\\:overlapping\\:words'}{{total\\:words\\:in\\:the\\:reference\\:summary}} \\big) $$ \n",
    "\n",
    "$$ \\text{Recall} = \\big( \\frac{6}{6} \\big)  = {1.0}$$  \n",
    "\n",
    "This means that all the words in the reference summary have been captured by the system summary, which indeed is the case for this example.\n",
    "\n",
    "This looks really good for a text summarization system. But it does not tell you the other side of the story. A machine generated summary (system summary) can be extremely long, capturing all words in the reference summary. But, many of the words in the system summary may be useless, making the summary unnecessarily verbose.\n",
    "\n",
    "This is where precision comes into play. In terms of precision, what you are essentially measuring is, how much of the system summary was in fact relevant or needed? Precision is measured as:\n",
    "\n",
    "$$  \\big( \\frac{number\\:of\\:overlapping\\:words'}{{total\\:words\\:in\\:the\\:system\\:summary}} \\big) $$ \n",
    "\n",
    "$$ \\text{Precision} = \\big( \\frac{6}{7} \\big)  = {0.86}$$  \n",
    "\n",
    "Now, let's say System Summary 2: \n",
    "\n",
    "`the tiny little cat was found under the big funny bed`\n",
    "\n",
    "The Precision now becomes:\n",
    "\n",
    "$$ \\text{Precision} = \\big( \\frac{6}{11} \\big)  = {0.55}$$  \n",
    "\n",
    "Now, this doesn’t look so good, does it? That is because we have quite a few unnecessary words in the summary. The precision aspect becomes really crucial when you are trying to generate summaries that are concise in nature. Therefore, it is always best to compute both the precision and recall and then report the F-Measure.\n",
    "\n",
    "If your summaries are in some way forced to be concise through some constraints, then you could consider using just the recall, since precision is of less concern in this scenario.\n",
    "\n",
    "ROUGE-N, ROUGE-S, and ROUGE-L can be thought of as the granularity of texts being compared between the system summaries and reference summaries.\n",
    "\n",
    "* ROUGE-N — measures unigram, bigram, trigram and higher order n-gram overlap\n",
    "* ROUGE-L — measures longest matching sequence of words using LCS. An advantage of using LCS is that it does not require consecutive matches but in-sequence matches that reflect sentence level word order. Since it automatically includes longest in-sequence common n-grams, you don’t need a predefined n-gram length.\n",
    "* ROUGE-S — Is any pair of words in a sentence in order, allowing for arbitrary gaps. This can also be called skip-gram concurrence. For example, skip-bigram measures the overlap of word pairs that can have a maximum of two gaps in between words. As an example, for the phrase “cat in the hat” the skip-bigrams would be “cat in, cat the, cat hat, in the, in hat, the hat”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654eb16-8c7c-4cda-b5c3-275ddc62d7e3",
   "metadata": {
    "id": "c654eb16-8c7c-4cda-b5c3-275ddc62d7e3"
   },
   "source": [
    "### Q1. Please implement Rouge Score as our evaluation metric as a function that is called the for-loop (3 pt)\n",
    "Hint: similar to BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f5e378-e8d4-434c-a9ec-1017588d50d4",
   "metadata": {
    "id": "42f5e378-e8d4-434c-a9ec-1017588d50d4"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, actuals, tokenizer):\n",
    "    \n",
    "    # <your code here>\n",
    "    pred_len = predictions.shape[0]\n",
    "    \n",
    "    tok_act = tokenizer(actuals)\n",
    "    \n",
    "    rouge = predictions[predictions == tok_act].shape[0] / pred_len\n",
    "\n",
    "    return rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94b1834-d91b-4489-9680-d4959fd9f584",
   "metadata": {
    "id": "e94b1834-d91b-4489-9680-d4959fd9f584"
   },
   "outputs": [],
   "source": [
    "def Trainer(\n",
    "    dataset, source_text, target_text, model_params, output_dir=\"./outputs/\", device = \"cuda\"\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    trainer\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\n",
    "    # tokenzier for encoding the text\n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    if \"bart\" in model_params[\"MODEL\"]:\n",
    "        tokenizer = BartTokenizer.from_pretrained(f'facebook/{model_params[\"MODEL\"]}')\n",
    "        model = BartForConditionalGeneration.from_pretrained(f'facebook/{model_params[\"MODEL\"]}')\n",
    "    elif \"t5\" in model_params[\"MODEL\"]:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    elif \"pegasus\" in model_params[\"MODEL\"]:\n",
    "        tokenizer = PegasusTokenizer.from_pretrained(f'google/{model_params[\"MODEL\"]}')\n",
    "        model = PegasusForConditionalGeneration.from_pretrained(f'google/{model_params[\"MODEL\"]}')\n",
    "    else:\n",
    "        raise ValueError(\"Undefined model\")\n",
    "        \n",
    "    model = model.to(device)\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    val_dataset = dataset[\"validation\"]\n",
    "    \n",
    "    console.print(f\"FULL Dataset: {dataset.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "    \n",
    "    del dataset\n",
    "    \n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = Dataset(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MODEL\"],\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "#         train = True,\n",
    "    )\n",
    "    val_set = Dataset(\n",
    "        val_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MODEL\"],\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "#         train = False,\n",
    "    )\n",
    "    \n",
    "    del train_dataset, val_dataset\n",
    "    \n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    val_params = {\n",
    "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "    \n",
    "    print(\"TRAIN LOADER: \", len(training_loader))\n",
    "    print(\"VAL LOADER: \", len(val_loader))\n",
    "    \n",
    "    del train_params, val_params\n",
    "    \n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
    "    )\n",
    "    \n",
    "    if model_params[\"SCHEDULER\"] == \"linear\":\n",
    "        scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n",
    "    \n",
    "    # Training loop\n",
    "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "\n",
    "        loss = train(epoch, tokenizer, model, device, training_loader, optimizer, scheduler)\n",
    "        losses.append(loss.cpu().numpy())\n",
    "\n",
    "        # evaluating test dataset        \n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        \n",
    "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir, f\"\"\"predictions_{model_params['MODEL']}_epoch{epoch}.csv\"\"\"))\n",
    "        print(\"SAVE TO CSV FINISHED\")\n",
    "        \n",
    "        \n",
    "        rouge = compute_metrics(predictions, actuals, tokenizer)\n",
    "        \n",
    "        rouge_df = pd.DataFrame.from_dict(rouge, orient='index')\n",
    "        rouge_df.to_csv(os.path.join(output_dir, f\"\"\"rouge_{model_params['MODEL']}_epoch{epoch}.csv\"\"\"))\n",
    "        print(\"SAVE ROUGE TO CSV FINISHED\")\n",
    "    \n",
    "    console.log(f\"[Saving Model]...\\n\")\n",
    "    # Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "    \n",
    "    # converting list to array\n",
    "    arr = np.array(losses)\n",
    "    np.save(os.path.join(output_dir, f\"\"\"losses_{model_params['MODEL']}_epoch{model_params['TRAIN_EPOCHS']}\"\"\"), arr)\n",
    "\n",
    "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(\n",
    "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
    "    )\n",
    "    console.print(\n",
    "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
    "    )\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d088318-d8d5-421e-8d9c-58a7b1381e58",
   "metadata": {
    "id": "0d088318-d8d5-421e-8d9c-58a7b1381e58"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6c8802-3454-4005-ac49-ba4a9b00eaf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a6c8802-3454-4005-ac49-ba4a9b00eaf9",
    "outputId": "23fa7faa-8186-4333-aa44-3ee16656ca1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configured device:  cuda:1\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda:1' if cuda.is_available() else 'cpu'\n",
    "print(\"configured device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65393688-b610-4eca-b678-379964242528",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "65393688-b610-4eca-b678-379964242528",
    "outputId": "dff215bf-ba1e-440c-a29f-1694f3788266"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7862c11dd58048ff8f8f294cfe8f1483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bdc8ec92214960b0712c4cfe5a7b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/954 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset xsum/default (download: 245.38 MiB, generated: 507.60 MiB, post-processed: Unknown size, total: 752.98 MiB) to /home/st122336/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1ccf60768940088ae37552b06fd415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36404b8e2e745289cde6475c928381b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c521c9ed0d490fab88b22336a6d4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset xsum downloaded and prepared to /home/st122336/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8ce90fa206401aac565fc8f1016937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = 'xsum'\n",
    "\n",
    "if data == 'cnn_dailymail':\n",
    "    dataset = load_dataset(data, '3.0.0')\n",
    "    source_text = \"article\"\n",
    "    target_text = \"highlights\"\n",
    "elif data == \"xsum\":\n",
    "    dataset = load_dataset(data)\n",
    "    source_text = \"document\"\n",
    "    target_text = \"summary\"\n",
    "else:\n",
    "    raise ValueError(\"Undefined dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba1ee9-27fe-487d-b6a9-bb6ee22ece5b",
   "metadata": {
    "id": "b1ba1ee9-27fe-487d-b6a9-bb6ee22ece5b"
   },
   "source": [
    "### Let's define model parameters specific to T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7379a76f-66ab-4635-bfd4-cc0c3268f0f2",
   "metadata": {
    "id": "7379a76f-66ab-4635-bfd4-cc0c3268f0f2"
   },
   "outputs": [],
   "source": [
    "# let's define model parameters specific to BART\n",
    "model_params = {\n",
    "    \"MODEL\": \"t5-small\",  # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\": 8,  # training batch size\n",
    "    \"VALID_BATCH_SIZE\": 8,  # validation batch size\n",
    "    \"TRAIN_EPOCHS\": 3,  # number of training epochs\n",
    "    \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
    "    \"LEARNING_RATE\": 2e-05,  # learning rate default betas=(0.9, 0.999), eps=1e-08\n",
    "    \"SCHEDULER\": \"linear\",\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\": 36,  # max length of target text\n",
    "    \"SEED\": 42,  # set seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c40942e4-523c-4890-9746-488830fedc35",
   "metadata": {
    "id": "c40942e4-523c-4890-9746-488830fedc35",
    "outputId": "1755522f-39c7-4b93-db57-580403986452"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05:27:39] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-small<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                      <a href=\"file:///tmp/ipykernel_114/1056334050.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1056334050.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_114/1056334050.py#18\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05:27:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-small\u001b[33m...\u001b[0m                                      \u001b]8;id=653847;file:///tmp/ipykernel_114/1056334050.py\u001b\\\u001b[2m1056334050.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=942417;file:///tmp/ipykernel_114/1056334050.py#18\u001b\\\u001b[2m18\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                  \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda25593ad9543899e0a8d2fcc94a9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f61c506b7b40d0b2ae465576c72b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1afa99f6c780463dafbb71b8366ddb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cc0d8393c549cf9ed3ff6e62f9fab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05:28:17] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                           <a href=\"file:///tmp/ipykernel_114/1056334050.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1056334050.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_114/1056334050.py#38\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05:28:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                           \u001b]8;id=587636;file:///tmp/ipykernel_114/1056334050.py\u001b\\\u001b[2m1056334050.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=351379;file:///tmp/ipykernel_114/1056334050.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                  \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'train'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204045</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'validation'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11332</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'test'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11334</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m{\u001b[0m\u001b[32m'train'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m204045\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'validation'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m11332\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'test'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m11334\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204045</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m204045\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11332</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m11332\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN LOADER:  125\n",
      "VAL LOADER:  125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05:28:18] </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                      <a href=\"file:///tmp/ipykernel_114/1056334050.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1056334050.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_114/1056334050.py#105\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05:28:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                      \u001b]8;id=197735;file:///tmp/ipykernel_114/1056334050.py\u001b\\\u001b[2m1056334050.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=191679;file:///tmp/ipykernel_114/1056334050.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                 \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  0 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   | 0/125 | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   | 0/125 | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  10 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  20 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  30 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  40 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  50 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  60 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  70 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 70/125 | tensor(6.2952, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 70/125 | tensor(6.2952, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  80 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 70/125 | tensor(6.2952, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 80/125 | tensor(5.8856, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 70/125 | tensor(6.2952, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 80/125 | tensor(5.8856, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  90 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                                </span>\n",
       "+----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 70/125 | tensor(6.2952, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 80/125 | tensor(5.8856, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 90/125 | tensor(5.5936, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                                \u001b[0m\n",
       "+----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+--------+------------------------------------------------------------|\n",
       "|  0   | 0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125 | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125 | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125 | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125 | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125 | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125 | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 70/125 | tensor(6.2952, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 80/125 | tensor(5.8856, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 90/125 | tensor(5.5936, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  100 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                Training Status                                </span>\n",
       "+-----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\">  Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+---------+------------------------------------------------------------|\n",
       "|  0   |  0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125  | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125  | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125  | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125  | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125  | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125  | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 70/125  | tensor(6.2952, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 80/125  | tensor(5.8856, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 90/125  | tensor(5.5936, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 100/125 | tensor(5.3247, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+-----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                Training Status                                \u001b[0m\n",
       "+-----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m Steps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+---------+------------------------------------------------------------|\n",
       "|  0   |  0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125  | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125  | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125  | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125  | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125  | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125  | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 70/125  | tensor(6.2952, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 80/125  | tensor(5.8856, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 90/125  | tensor(5.5936, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 100/125 | tensor(5.3247, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+-----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  110 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                Training Status                                </span>\n",
       "+-----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\">  Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+---------+------------------------------------------------------------|\n",
       "|  0   |  0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125  | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125  | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125  | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125  | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125  | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125  | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 70/125  | tensor(6.2952, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 80/125  | tensor(5.8856, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 90/125  | tensor(5.5936, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 100/125 | tensor(5.3247, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 110/125 | tensor(5.3783, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+-----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                Training Status                                \u001b[0m\n",
       "+-----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m Steps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+---------+------------------------------------------------------------|\n",
       "|  0   |  0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125  | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125  | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125  | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125  | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125  | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125  | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 70/125  | tensor(6.2952, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 80/125  | tensor(5.8856, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 90/125  | tensor(5.5936, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 100/125 | tensor(5.3247, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 110/125 | tensor(5.3783, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+-----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:  120 / 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                Training Status                                </span>\n",
       "+-----------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\">  Steps  </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+---------+------------------------------------------------------------|\n",
       "|  0   |  0/125  | tensor(6.9166, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 10/125  | tensor(6.0950, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 20/125  | tensor(6.0341, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 30/125  | tensor(6.6680, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 40/125  | tensor(6.0066, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 50/125  | tensor(5.5205, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 60/125  | tensor(5.8240, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 70/125  | tensor(6.2952, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 80/125  | tensor(5.8856, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 90/125  | tensor(5.5936, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 100/125 | tensor(5.3247, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 110/125 | tensor(5.3783, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 120/125 | tensor(5.4052, device='cuda:1', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+-----------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                Training Status                                \u001b[0m\n",
       "+-----------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m Steps \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+---------+------------------------------------------------------------|\n",
       "|  0   |  0/125  | tensor(6.9166, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 10/125  | tensor(6.0950, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 20/125  | tensor(6.0341, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 30/125  | tensor(6.6680, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 40/125  | tensor(6.0066, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 50/125  | tensor(5.5205, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 60/125  | tensor(5.8240, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 70/125  | tensor(6.2952, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 80/125  | tensor(5.8856, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 90/125  | tensor(5.5936, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 100/125 | tensor(5.3247, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 110/125 | tensor(5.3783, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 120/125 | tensor(5.4052, device='cuda:1', grad_fn=<NllLossBackward0>)|\n",
       "+-----------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m30\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m40\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m60\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m70\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m80\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m90\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m110\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m120\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './outputs/predictions_t5-small_epoch0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114/571082236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m Trainer(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msource_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_114/1056334050.py\u001b[0m in \u001b[0;36mTrainer\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Generated Text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Actual Text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"\"\"predictions_{model_params['MODEL']}_epoch{epoch}.csv\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SAVE TO CSV FINISHED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './outputs/predictions_t5-small_epoch0.csv'"
     ]
    }
   ],
   "source": [
    "console = Console(record=True)\n",
    "\n",
    "training_logger = Table(\n",
    "    Column(\"Epoch\", justify=\"center\"),\n",
    "    Column(\"Steps\", justify=\"center\"),\n",
    "    Column(\"Loss\", justify=\"center\"),\n",
    "    title=\"Training Status\",\n",
    "    pad_edge=False,\n",
    "    box=box.ASCII,\n",
    ")\n",
    "\n",
    "Trainer(\n",
    "    dataset=dataset,\n",
    "    source_text=source_text, \n",
    "    target_text=target_text,\n",
    "    model_params=model_params,\n",
    "    output_dir=f\"\"\"./outputs/\"\"\",\n",
    "    device = device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53d1cbf-a541-4f96-b4bf-978b35bdb629",
   "metadata": {
    "id": "f53d1cbf-a541-4f96-b4bf-978b35bdb629"
   },
   "source": [
    "#### But is ROUGE score the best metric to evaluatate a summary?\n",
    "\n",
    "Here are examples of the generated text. Let's take a closer look at the results.\n",
    "\n",
    "##### Example 1:\n",
    "\n",
    "![](images/generatedexample.png)\n",
    "\n",
    "At the highlighted row, you will notice that in the Generated Text, it exists `Graeme Roy`, while the Actual Summary it is `Jason Roy`\n",
    "\n",
    "##### Example 2:\n",
    "\n",
    "![](images/generatedtext.png)\n",
    "\n",
    "![](images/actualtext.png)\n",
    "\n",
    "You can see that the name `Yvette Cooper` is contained in the sample **8th** of the Actual Summary, but it appeared in the sample **71st** of the Generated Text.\n",
    "\n",
    "This problem is called **Name Entity Halluciation**  which is one of comon problems found in Text Summarization task. Since summarization models are optimized to generate summaries that highly overlap with human references, the faithfulness of the summary is not guaranteed. ROUGE Score is insensitive to semantic errors.\n",
    "\n",
    "These n-gram based approaches weight all portions of the text equally, even when only a small fraction of the n-grams carry most of the semantic content. As a result, factual inconsistency caused by small changes may be drowned out by otherwise high n-gram overlap. \n",
    "\n",
    "Another type of problem is called **Factual Consistency** <br>\n",
    "For example: <br>\n",
    "the sentence: `My name is Beau.` and <br> \n",
    "the sentence: `My name is not Beau.` <br>\n",
    "share nearly all unigrams and bigrams despite having the opposite meaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec221e15-4873-43e6-934a-ca2fc461196e",
   "metadata": {
    "id": "ec221e15-4873-43e6-934a-ca2fc461196e"
   },
   "source": [
    "### Q2. Please spend some time explore 2 useful metrices that can be used to evaluate summary. Explain what they are briefly and explain how they could be useful and why could they not. (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b9d6e-5d3c-4917-95ff-957243ca8ad9",
   "metadata": {
    "id": "7b5b9d6e-5d3c-4917-95ff-957243ca8ad9"
   },
   "source": [
    "#### <font color=\"red\">Write your answer here.</font> \n",
    "The following are the two possible metrics to evaluate summary.\n",
    "\n",
    "BERTSCORE. This metric measures the dissimilarity of embedding between the proposed solution and the ground truth. This metric can be useful for summary because with BERT one word can have different embedding depending of the input. Moreover, BERT seems to be a good general model. Nevertheless, if we use Bertscore as measure we're loosing of justification. It is impossible for the moment to clearly explain what's happening in a neural network. \n",
    "\n",
    "BLANC. BLANC metric can be divided in two different metris: BLANC tune and BLANC help. In BLANC-tune, a BERT model learnt from the summary proposed. Then, we see how read the summary helped the BERT model to fill out masked tokens from the input text. BLANC-help measures the impact of the unmasking in a similar way. As we can see, BLANC can be useful in measuring how the model improves after seen the summary. Nevertheless, what we don't know is how the summary helped the model or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b854f9-0416-4ef4-844e-f4c1089405b9",
   "metadata": {
    "id": "11b854f9-0416-4ef4-844e-f4c1089405b9"
   },
   "source": [
    "### Reference:\n",
    "https://paperswithcode.com/method/t5#:~:text=T5%2C%20or%20Text%2Dto%2D,to%20generate%20some%20target%20text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05920693-935a-453e-845c-85edd19c06a7",
   "metadata": {
    "id": "05920693-935a-453e-845c-85edd19c06a7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "A5 Seq2Seq Part II.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
